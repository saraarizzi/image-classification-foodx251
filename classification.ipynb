{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "ng_mMWEpvI4X"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1><b>FoodX-251 Image Classification</b></h1>\n",
        "\n",
        "<b>Visual Information Processing and Management Exam\n",
        "\n",
        "Sara Arizzi 845374</b>\n",
        "\n",
        "<hr>"
      ],
      "metadata": {
        "id": "TpjLmc4u_T9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN = True  # Set to True if you want to retrain all the models\n",
        "GDRIVE = True  # Set to False if you are running on local env"
      ],
      "metadata": {
        "id": "Sp8xJEcvHF-E"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "mr2HvZDkAvD8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "6fyF7I7RAwg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# ! pip install torchinfo"
      ],
      "metadata": {
        "id": "aC9ylrtbHg4T"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "udqqMZp08usz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from zipfile import ZipFile\n",
        "import numpy as np\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "# pytorch\n",
        "import torch\n",
        "from torch import nn\n",
        "# from torchinfo import summary\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.models import mobilenet_v3_small, MobileNet_V3_Small_Weights\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# device\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# seeds\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "random.seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Path"
      ],
      "metadata": {
        "id": "X4KgB8kEAzGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount GDrive or set working dir\n",
        "if GDRIVE:\n",
        "  from google.colab import drive\n",
        "  drive.mount(\"/content/drive\")\n",
        "\n",
        "  DATA_PATH = os.path.join(*[\"drive\", \"MyDrive\", \"Visual\", \"data\"])\n",
        "else:\n",
        "  DATA_PATH = os.path.join(*[\"something\", \"something\", \"data\"])\n",
        "  TRAIN_PATH = \"\"\n",
        "  VAL_PATH = \"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jKgq619AueA",
        "outputId": "cc265282-e946-496e-84bf-b7da72e394d5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy and unzip train and val if GDrive\n",
        "if GDRIVE:\n",
        "  shutil.copyfile(os.path.join(*[DATA_PATH, \"clean\", \"train.zip\"]), \"train.zip\")\n",
        "  shutil.copyfile(os.path.join(*[DATA_PATH, \"clean\", \"val.zip\"]), \"val.zip\")\n",
        "  # shutil.copyfile(os.path.join(DATA_PATH, \"val_degraded.zip\"), \"val_degraded.zip\")\n",
        "\n",
        "  with ZipFile(\"train.zip\", \"r\") as zf:\n",
        "    zf.extractall()\n",
        "\n",
        "  with ZipFile(\"val.zip\", \"r\") as zf:\n",
        "    zf.extractall()\n",
        "\n",
        "  # with ZipFile(\"val_degraded.zip\", \"r\") as zf:\n",
        "    # zf.extractall()\n",
        "\n",
        "  TRAIN_PATH = os.path.join(\"content\", \"train\")\n",
        "  VAL_PATH = os.path.join(\"content\", \"val\")\n",
        "  # VAL_DEGRADED_PATH = os.path.join(\"content\", \"val_degraded\")"
      ],
      "metadata": {
        "id": "MW6LeAeS-1kI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "a52bda3a-b167-4e51-b9c8-9ca134ea836c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-d1f642cdec48>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Copy and unzip train and val if GDrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mGDRIVE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"clean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train.zip\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train.zip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"clean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val.zip\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val.zip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# shutil.copyfile(os.path.join(DATA_PATH, \"val_degraded.zip\"), \"val_degraded.zip\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    265\u001b[0m                     \u001b[0;32melif\u001b[0m \u001b[0m_USE_CP_SENDFILE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m                             \u001b[0m_fastcopy_sendfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m                             \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0m_GiveupOnFastCopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36m_fastcopy_sendfile\u001b[0;34m(fsrc, fdst)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;31m# ...in oder to have a more informative exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"All data is located at: {DATA_PATH}\\n\"\n",
        "      f\"Trainset is at: {TRAIN_PATH}\\n\"\n",
        "      f\"Valset is at: {VAL_PATH}\\n\"\n",
        "      # f\"Valset degraded is at: {VAL_DEGRADED_PATH}\\n\"\n",
        "      )"
      ],
      "metadata": {
        "id": "dspqxaT2-0zK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Data"
      ],
      "metadata": {
        "id": "jkmthkTeCPt8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "rL06dZG--Tjp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training functions"
      ],
      "metadata": {
        "id": "ng_mMWEpvI4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_at_k(predictions, y_one_hot, k=1):\n",
        "    \"\"\"\n",
        "    Calculate the top-k accuracy.\n",
        "\n",
        "    Args:\n",
        "    - predictions (torch.Tensor): Tensor of shape (batch_size, num_classes) containing the model's predicted scores.\n",
        "    - y_one_hot (torch.Tensor): One-hot encoded ground truth tensor of shape (batch_size, num_classes).\n",
        "    - k (int): Number of top predictions to consider for accuracy.\n",
        "\n",
        "    Returns:\n",
        "    - accuracy (float): The top-k accuracy score.\n",
        "    \"\"\"\n",
        "    # Convert one-hot encoded ground truth to label indices\n",
        "    y_true = torch.argmax(y_one_hot, dim=1)\n",
        "\n",
        "    # Get the top-k predicted indices along the last dimension (num_classes)\n",
        "    _, top_k_indices = torch.topk(predictions, k, dim=1)\n",
        "\n",
        "    # Check if the true labels are in the top-k indices\n",
        "    correct = top_k_indices.eq(y_true.view(-1, 1).expand_as(top_k_indices))\n",
        "\n",
        "    # Calculate the accuracy\n",
        "    accuracy = correct.float().sum() / predictions.size(0)\n",
        "\n",
        "    return accuracy.item()"
      ],
      "metadata": {
        "id": "pWx24Y2Y3GfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5JLzaiTEvZt"
      },
      "outputs": [],
      "source": [
        "def train_step(model, data_loader, loss_fn, optimizer,\n",
        "               device, lambda_value=0, regularization=0, scheduler=None):\n",
        "    train_loss, train_acc1, train_acc3, train_acc5 = 0, 0, 0, 0\n",
        "\n",
        "    for batch, (X, y) in enumerate(data_loader):\n",
        "        # Send data to GPU\n",
        "        X, y = X.to(device), y.type(torch.LongTensor).to(device)\n",
        "        y_one_hot = torch.nn.functional.one_hot(y, num_classes=251).float()\n",
        "\n",
        "        # Forward Pass\n",
        "        y_pred = model(X)\n",
        "        y_pred = y_pred.squeeze()\n",
        "\n",
        "        # Calculate Loss\n",
        "        loss = loss_fn(y_pred, y_one_hot) + lambda_value * regularization\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # Optimizer reset step\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Loss Backpropagation\n",
        "        loss.backward(retain_graph=True)\n",
        "\n",
        "        # Optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        train_acc1 += accuracy_at_k(y_pred, y_one_hot, 1)\n",
        "        train_acc3 += accuracy_at_k(y_pred, y_one_hot, 3)\n",
        "        train_acc5 += accuracy_at_k(y_pred, y_one_hot, 5)\n",
        "\n",
        "        # Clean Cache\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # Scheduler step\n",
        "    lr = None\n",
        "    if scheduler is not None:\n",
        "        scheduler.step()\n",
        "        lr = scheduler.get_last_lr()\n",
        "\n",
        "    # Print loss and accuracy\n",
        "    train_loss /= len(data_loader)\n",
        "    train_acc1 /= len(data_loader)\n",
        "    train_acc3 /= len(data_loader)\n",
        "    train_acc5 /= len(data_loader)\n",
        "\n",
        "    return train_loss, train_acc1, train_acc3, train_acc5, lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MyWSVTWGPUc"
      },
      "outputs": [],
      "source": [
        "def val_step(model, data_loader, loss_fn, device):\n",
        "    val_loss, val_acc1, val_acc3, val_acc5 = 0, 0, 0, 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for batch, (X, y) in enumerate(data_loader):\n",
        "            # Send data to GPU\n",
        "            X, y = X.to(device), y.type(torch.LongTensor).to(device)\n",
        "            y_one_hot = torch.nn.functional.one_hot(y, num_classes=251).float()\n",
        "\n",
        "            # Forward pass\n",
        "            val_pred = model(X)\n",
        "            val_pred = val_pred.squeeze()\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = loss_fn(val_pred, y_one_hot)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            val_acc1 += accuracy_at_k(val_pred, y_one_hot, 1)\n",
        "            val_acc3 += accuracy_at_k(val_pred, y_one_hot, 3)\n",
        "            val_acc5 += accuracy_at_k(val_pred, y_one_hot, 5)\n",
        "\n",
        "            # Clean Cache\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    val_loss /= len(data_loader)\n",
        "    val_acc1 /= len(data_loader)\n",
        "    val_acc3 /= len(data_loader)\n",
        "    val_acc5 /= len(data_loader)\n",
        "\n",
        "    return val_loss, val_acc1, val_acc3, val_acc5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PDiFqVh2PGH"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, test_loader, optimizer, loss_fn,\n",
        "          epochs, device, lambda_value=0, regularization=0, scheduler=None):\n",
        "    results = {\n",
        "        \"train_loss\": [],\n",
        "        \"train_acc1\": [],\n",
        "        \"train_acc3\": [],\n",
        "        \"train_acc5\": [],\n",
        "        \"val_loss\": [],\n",
        "        \"val_acc1\": [],\n",
        "        \"val_acc3\": [],\n",
        "        \"val_acc5\": []\n",
        "    }\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_loss, ta1, ta3, ta5, lr = train_step(model=model,\n",
        "                                                   data_loader=train_loader,\n",
        "                                                   loss_fn=loss_fn,\n",
        "                                                   optimizer=optimizer,\n",
        "                                                   scheduler=scheduler,\n",
        "                                                   device=device,\n",
        "                                                   lambda_value=lambda_value,\n",
        "                                                   regularization=regularization\n",
        "                                                   )\n",
        "        val_loss, va1, va3, va5 = val_step(model=model,\n",
        "                                           data_loader=test_loader,\n",
        "                                           loss_fn=loss_fn,\n",
        "                                           device=device)\n",
        "        # Print out what's happening\n",
        "        print(\n",
        "            f\"Epoch: {epoch} --> \\t\"\n",
        "            f\"train_loss: {train_loss:.4f} | \"\n",
        "            f\"val_loss: {val_loss:.4f} | \"\n",
        "            f\"ta@1: {ta1:.4f} | \"\n",
        "            f\"ta@3: {ta3:.4f} | \"\n",
        "            f\"ta@5: {ta5:.4f} | \"\n",
        "            f\"va@1: {va1:.4f} | \"\n",
        "            f\"va@3: {va3:.4f} | \"\n",
        "            f\"va@5: {va5:.4f} | \"\n",
        "            f\"LR: {lr} \"\n",
        "        )\n",
        "\n",
        "        # Update results dictionary\n",
        "        results[\"train_loss\"].append(train_loss)\n",
        "        results[\"train_acc1\"].append(ta1)\n",
        "        results[\"train_acc3\"].append(ta3)\n",
        "        results[\"train_acc5\"].append(ta5)\n",
        "        results[\"val_loss\"].append(val_loss)\n",
        "        results[\"val_acc1\"].append(va1)\n",
        "        results[\"val_acc3\"].append(va3)\n",
        "        results[\"val_acc5\"].append(va5)\n",
        "\n",
        "    # Return the filled results at the end of the epochs\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MobileNet V3"
      ],
      "metadata": {
        "id": "SnceGO0e-VxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mob_net(weights=None):\n",
        "  mod = mobilenet_v3_small(weights=weights)\n",
        "\n",
        "  # Change to 251 output class\n",
        "  mod.classifier[3] = nn.Linear(\n",
        "      in_features=mod.classifier[3].in_features,\n",
        "      out_features=251, bias=True)\n",
        "\n",
        "  return mod"
      ],
      "metadata": {
        "id": "ojinjJko-ZD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```python\n",
        "summary(\n",
        "  model=get_res_net(),\n",
        "  input_size=(32, 3, 224, 224),\n",
        "  col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "  col_width=20,\n",
        "  row_settings=[\"var_names\"]\n",
        ")\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "nBmaLtXeNMnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((224, 224))\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((224, 224))\n",
        "])\n",
        "train_dataset = ImageFolder(\"train\", transform=train_transforms)\n",
        "val_dataset = ImageFolder(\"val\", transform=val_transforms)"
      ],
      "metadata": {
        "id": "TiAQgx2aq9Lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### From Scratch"
      ],
      "metadata": {
        "id": "eWOuzWXZqpxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper Parameters\n",
        "BATCH_SIZE = 256\n",
        "EPOCHS = 100\n",
        "LOSS_FN = nn.CrossEntropyLoss()\n",
        "LEARNING_RATE = 1e-3\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "m = get_mob_net()\n",
        "optimizer = torch.optim.Adam(m.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-4)\n",
        "m = m.to(DEVICE)\n",
        "\n",
        "model_path = os.path.join(*[DATA_PATH, \"saved_models\", \"mobilenetv3_from_scratch.pt\"])\n",
        "history_path = os.path.join(*[DATA_PATH, \"saved_models\", \"history_mobilenetv3_from_scratch.pkl\"])\n",
        "if TRAIN:\n",
        "  history = train(m, train_loader, val_loader, optimizer,\n",
        "                LOSS_FN, EPOCHS, DEVICE, scheduler=scheduler)\n",
        "  torch.save(m.state_dict(), model_path)\n",
        "  pickle.dump(history, open(history_path, \"wb\"))\n",
        "else:\n",
        "  m.load_state_dict(torch.load(model_path, map_location=torch.device(DEVICE)))\n",
        "  history = pickle.load(open(history_path, \"rb\"))"
      ],
      "metadata": {
        "id": "KC8CSh85-rIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fine-tuned"
      ],
      "metadata": {
        "id": "6Tmns4_rqOn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper Parameters\n",
        "BATCH_SIZE = 256\n",
        "EPOCHS = 10\n",
        "LOSS_FN = nn.CrossEntropyLoss()\n",
        "LEARNING_RATE = 1e-4\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "m = get_mob_net(weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1)\n",
        "optimizer = torch.optim.Adam(m.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-5)\n",
        "m = m.to(DEVICE)\n",
        "\n",
        "model_path = os.path.join(*[DATA_PATH, \"saved_models\", \"mobilenetv3_finetuned.pt\"])\n",
        "history_path = os.path.join(*[DATA_PATH, \"saved_models\", \"history_mobilenetv3_finetuned.pkl\"])\n",
        "if False:\n",
        "  history = train(m, train_loader, val_loader, optimizer,\n",
        "                LOSS_FN, EPOCHS, DEVICE, scheduler=scheduler)\n",
        "  torch.save(m.state_dict(), model_path)\n",
        "  pickle.dump(history, open(history_path, \"wb\"))\n",
        "else:\n",
        "  m.load_state_dict(torch.load(model_path, map_location=torch.device(DEVICE)))\n",
        "  history = pickle.load(open(history_path, \"rb\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-W8VhMKw_EVt",
        "outputId": "8b6f81ba-962a-4ebe-8c06-6978c0b2d6da"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\n",
            "100%|██████████| 9.83M/9.83M [00:00<00:00, 52.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 --> \ttrain_loss: 4.3920 | val_loss: 3.0274 | ta@1: 0.1393 | ta@3: 0.2530 | ta@5: 0.3169 | va@1: 0.3242 | va@3: 0.5160 | va@5: 0.6104 | LR: [9.779754323328192e-05] \n",
            "Epoch: 1 --> \ttrain_loss: 2.8595 | val_loss: 2.4030 | ta@1: 0.3690 | ta@3: 0.5570 | ta@5: 0.6372 | va@1: 0.4265 | va@3: 0.6335 | va@5: 0.7141 | LR: [9.140576474687264e-05] \n",
            "Epoch: 2 --> \ttrain_loss: 2.4952 | val_loss: 2.2419 | ta@1: 0.4431 | ta@3: 0.6327 | ta@5: 0.7046 | va@1: 0.4648 | va@3: 0.6627 | va@5: 0.7434 | LR: [8.14503363531613e-05] \n",
            "Epoch: 3 --> \ttrain_loss: 2.2965 | val_loss: 2.1441 | ta@1: 0.4860 | ta@3: 0.6704 | ta@5: 0.7389 | va@1: 0.4840 | va@3: 0.6798 | va@5: 0.7549 | LR: [6.890576474687264e-05] \n",
            "Epoch: 4 --> \ttrain_loss: 2.1519 | val_loss: 2.0913 | ta@1: 0.5165 | ta@3: 0.6979 | ta@5: 0.7609 | va@1: 0.4901 | va@3: 0.6904 | va@5: 0.7668 | LR: [5.500000000000001e-05] \n",
            "Epoch: 5 --> \ttrain_loss: 2.0313 | val_loss: 2.0656 | ta@1: 0.5431 | ta@3: 0.7172 | ta@5: 0.7802 | va@1: 0.5014 | va@3: 0.6954 | va@5: 0.7700 | LR: [4.109423525312737e-05] \n",
            "Epoch: 6 --> \ttrain_loss: 1.9374 | val_loss: 2.0573 | ta@1: 0.5625 | ta@3: 0.7348 | ta@5: 0.7935 | va@1: 0.5009 | va@3: 0.6982 | va@5: 0.7703 | LR: [2.8549663646838717e-05] \n",
            "Epoch: 7 --> \ttrain_loss: 1.8619 | val_loss: 2.0410 | ta@1: 0.5790 | ta@3: 0.7471 | ta@5: 0.8041 | va@1: 0.5047 | va@3: 0.7047 | va@5: 0.7733 | LR: [1.8594235253127375e-05] \n",
            "Epoch: 8 --> \ttrain_loss: 1.8078 | val_loss: 2.0496 | ta@1: 0.5920 | ta@3: 0.7565 | ta@5: 0.8112 | va@1: 0.5049 | va@3: 0.7011 | va@5: 0.7697 | LR: [1.2202456766718093e-05] \n",
            "Epoch: 9 --> \ttrain_loss: 1.7713 | val_loss: 2.0439 | ta@1: 0.6006 | ta@3: 0.7620 | ta@5: 0.8162 | va@1: 0.5058 | va@3: 0.7016 | va@5: 0.7721 | LR: [1e-05] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 4))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.get(\"train_loss\"), label='Train')\n",
        "plt.plot(history.get(\"val_loss\"), label='Val')\n",
        "plt.legend()\n",
        "plt.title(\"Loss\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.get(\"train_acc1\"), label='Train Acc@1', ls=\"-\", color=\"gray\")\n",
        "plt.plot(history.get(\"train_acc3\"), label='Train Acc@3', ls=\"-\", color=\"gray\")\n",
        "plt.plot(history.get(\"train_acc5\"), label='Train Acc@5', ls=\"-\", color=\"gray\")\n",
        "plt.plot(history.get(\"val_acc1\"), label='Val Acc@1', color=\"blue\")\n",
        "plt.plot(history.get(\"val_acc3\"), label='Val Acc@3', color=\"blue\")\n",
        "plt.plot(history.get(\"val_acc5\"), label='Val Acc@5', color=\"blue\")\n",
        "plt.legend()\n",
        "plt.title(\"Accuracy\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dN05-IzWzLNc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}